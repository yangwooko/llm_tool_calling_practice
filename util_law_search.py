import json
import requests
from typing import List, Dict, Any, Callable
import inspect
import os
from dotenv import load_dotenv
import psycopg2
from util_tool_call import SimpleToolCaller
import re

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()


# ë²•ë ¹ ê²€ìƒ‰ í´ë˜ìŠ¤
class LawSearcher:
    def __init__(self):
        self.search_results = []
        self.search_results_dict = {}
        self.current_index = 0
        self.last_query = None

    def extract_first_number(self, text):
        if text == "ì¡°í•­ ë²ˆí˜¸ ì—†ìŒ":
            return None

        # íŠ¹ì • ë¬¸ìì—´ íŒ¨í„´ì„ ë¨¼ì € ì°¾ìŒ (ì˜ˆ: "ë³„í‘œ" ë˜ëŠ” "ë¶€ì¹™"ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°)
        special_pattern = r"^(ë³„í‘œ|ë³„ì§€|ë¶€ì¹™)\d+"
        special_match = re.match(special_pattern, text)

        # íŠ¹ì • ë¬¸ìì—´ íŒ¨í„´ì— ë§¤ì¹­ë˜ë©´ í•´ë‹¹ ë¬¸ìì—´ ë°˜í™˜
        if special_match:
            return special_match.group()

        # ì¼ë°˜ ìˆ«ìë§Œ ì¶”ì¶œí•˜ëŠ” íŒ¨í„´
        match = re.search(r"\d+", text)
        if match:
            return match.group()

        # ì•„ë¬´ê²ƒë„ ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜
        return None

    def parse_law_results(self, text):
        # ë§¨ ì•ì— ë²•ë¥ ê³¼ ì¡°í•­: ì´ ìˆìœ¼ë©´ ë¬´ì‹œ
        text = text.split("ë²•ë¥ ê³¼ ì¡°í•­:")[1].strip()
        # ì•ì— \n ë“±ì´ ìˆìœ¼ë©´ ì œê±°
        text = text.lstrip("\n")
        print("ğŸ” TEXT-->", text)
        # ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ë²•ë¥ ëª…ê³¼ ì¡°í•­ ë²ˆí˜¸ ì¶”ì¶œ
        pattern = r'ë²•ë¥ ëª…:\s*"([^"]+)",\s*ì¡°í•­ ë²ˆí˜¸:\s*"([^"]+)"'
        print("ğŸ” PATTERN-->", 1)

        # ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ ëª¨ë“  ë§¤ì¹­ëœ ê²°ê³¼ë¥¼ ì°¾ìŒ
        matches = re.findall(pattern, text)
        print("ğŸ” PATTERN-->", 2)

        # ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
        result_list = []
        print("ğŸ” PATTERN-->", 3)

        # ë§¤ì¹­ëœ ê²°ê³¼ë¥¼ ìˆœíšŒí•˜ë©° ë¦¬ìŠ¤íŠ¸ì— ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì¶”ê°€
        for match in matches:
            print("ğŸ” MATCH-->", match)
            law_info = {
                "ë²•ë¥ ëª…": match[0],
                "ì¡°í•­ ë²ˆí˜¸": self.extract_first_number(match[1]),
            }
            result_list.append(law_info)

        print("ğŸ” RESULT LIST-->", result_list)
        return result_list

    def search_laws(self, query: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ì— ê´€ë ¨ëœ ë²•ë ¹ë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤. í˜¸ì¶œí•  ë•Œë§ˆë‹¤ ë‹¤ìŒ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # ìƒˆë¡œìš´ ì¿¼ë¦¬ì¸ ê²½ìš° ê²€ìƒ‰ ìˆ˜í–‰
        if query != self.last_query:
            self.search_results = []
            self.search_results_dict = {}
            self.current_index = 0
            self.last_query = query

            # LLMì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë²•ë ¹ ì´ë¦„ì´ ìˆë‹¤ë©´ ì¶”ì¶œí•©ë‹ˆë‹¤.
            messages_law_name = [
                {
                    "role": "system",
                    "content": """ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ëª¨ë“  ë²•ë¥ ëª…ê³¼ ì¡°í•­ ë²ˆí˜¸ë¥¼ ê°ê° ì¶”ì¶œí•´ì¤˜. ê° ë²•ë¥ ëª…ê³¼ ì¡°í•­ ë²ˆí˜¸ë¥¼ ìˆœì„œëŒ€ë¡œ ì¶”ì¶œí•˜ê³ , ì¡°í•­ ë²ˆí˜¸ê°€ ì—†ëŠ” ê²½ìš°ì—ëŠ” "ì¡°í•­ ë²ˆí˜¸ ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œí•´ì¤˜. ë§Œì•½ ì§ˆë¬¸ì— ë²•ë¥ , ì‹œí–‰ë ¹, ì‹œí–‰ê·œì¹™, ìì¹˜ë²•ê·œ, í–‰ì •ê·œì¹™ì— ëŒ€í•œ ëª…ì‹œì ì¸ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ ë²•ë¥ ëª…ì— "í•´ë‹¹ì—†ìŒ"ìœ¼ë¡œ ì‘ë‹µì„ í•´. í–‰ì •ê·œì¹™ì€ "ê±´ì¶•ê³µì‚¬ ê°ë¦¬ì„¸ë¶€ê¸°ì¤€"ì²˜ëŸ¼ ~ê¸°ì¤€ìœ¼ë¡œ ëœ ê²½ìš°ë„ ìˆìœ¼ë‹ˆ ì´ê²ƒë„ ë²•ë¥ ëª…ìœ¼ë¡œ ì¸ì‹í•´ì•¼í•´.

ë¬¸ì¥: "ì •ì›ì˜ ì¡°ì„± ë° ì§„í¥ì— ê´€í•œ ë²•ë¥  ì œ18ì˜14ì¡°ì™€ ê°œì¸ì •ë³´ ë³´í˜¸ë²• ì œ5ì¡°ë¥¼ ì„¤ëª…í•´ì¤˜."
ë²•ë¥ ê³¼ ì¡°í•­: 
1. ë²•ë¥ ëª…: "ì •ì›ì˜ ì¡°ì„± ë° ì§„í¥ì— ê´€í•œ ë²•ë¥ ", ì¡°í•­ ë²ˆí˜¸: "ì œ18ì˜14ì¡°"
2. ë²•ë¥ ëª…: "ê°œì¸ì •ë³´ ë³´í˜¸ë²•", ì¡°í•­ ë²ˆí˜¸: "ì œ5ì¡°"

ë¬¸ì¥: "ì „ê¸°ê³µì‚¬ì—…ë²• ì‹œí–‰ê·œì¹™ ë³„ì§€ ì œ16í˜¸ ì„œì‹ì„ ì•Œë ¤ì¤˜."
ë²•ë¥ ê³¼ ì¡°í•­: 
1. ë²•ë¥ ëª…: "ì „ê¸°ê³µì‚¬ì—…ë²• ì‹œí–‰ê·œì¹™", ì¡°í•­ ë²ˆí˜¸: "ë³„ì§€16í˜¸"

ë¬¸ì¥: "ê±´ì¶•ê³µì‚¬ ê°ë¦¬ì„¸ë¶€ê¸°ì¤€ 2.5.6 ì•ˆì „ê´€ë¦¬"
ë²•ë¥ ê³¼ ì¡°í•­: 
1. ë²•ë¥ ëª…: "ê±´ì¶•ê³µì‚¬ ê°ë¦¬ì„¸ë¶€ê¸°ì¤€", ì¡°í•­ ë²ˆí˜¸: "2.5.6 ì•ˆì „ê´€ë¦¬"

ë¬¸ì¥: "ì •ë³´í†µì‹ ë§ ì´ìš©ì´‰ì§„ ë° ì •ë³´ë³´í˜¸ ë“±ì— ê´€í•œ ë²•ë¥  ì œ32ì¡° ì œ3í•­, ê³µê³µê¸°ê´€ì˜ ì •ë³´ê³µê°œì— ê´€í•œ ë²•ë¥  ì œ9ì¡°ë¥¼ ì•Œë ¤ì¤˜."
ë²•ë¥ ê³¼ ì¡°í•­: 
1. ë²•ë¥ ëª…: "ì •ë³´í†µì‹ ë§ ì´ìš©ì´‰ì§„ ë° ì •ë³´ë³´í˜¸ ë“±ì— ê´€í•œ ë²•ë¥ ", ì¡°í•­ ë²ˆí˜¸: "ì œ32ì¡° ì œ3í•­"
2. ë²•ë¥ ëª…: "ê³µê³µê¸°ê´€ì˜ ì •ë³´ê³µê°œì— ê´€í•œ ë²•ë¥ ", ì¡°í•­ ë²ˆí˜¸: "ì œ9ì¡°"

ë¬¸ì¥: "ë„ë¡œêµí†µë²•ê³¼ ì†Œë“ì„¸ë²• ì œ56ì¡°ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜."
ë²•ë¥ ê³¼ ì¡°í•­: 
1. ë²•ë¥ ëª…: "ë„ë¡œêµí†µë²•", ì¡°í•­ ë²ˆí˜¸: "ì¡°í•­ ë²ˆí˜¸ ì—†ìŒ"
2. ë²•ë¥ ëª…: "ì†Œë“ì„¸ë²•", ì¡°í•­ ë²ˆí˜¸: "ì œ56ì¡°"

ë¬¸ì¥: "ê±´ì„¤ì‚¬ì—…ê´€ë¦¬ê¸°ìˆ ì¸ì˜ ì„¤ê³„ë‹¨ê³„ ì—…ë¬´ ì¤‘ ì„¤ê³„ê²€í†  ê³„íšì— ëŒ€í•´ ì•Œë ¤ì¤˜."
ë²•ë¥ ê³¼ ì¡°í•­: 
1. ë²•ë¥ ëª…: "í•´ë‹¹ì—†ìŒ", ì¡°í•­ ë²ˆí˜¸: "í•´ë‹¹ì—†ìŒ"
""",
                },
                {"role": "user", "content": f"ë¬¸ì¥: {query}\në²•ë¥ ê³¼ ì¡°í•­: "},
            ]
            messages_keyword = [
                {
                    "role": "system",
                    "content": """ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ê²€ìƒ‰ì— ì‚¬ìš©í•  í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì¤˜. í‚¤ì›Œë“œëŠ” ë²•ë ¹ ì´ë¦„ì´ ì•„ë‹ˆë¼ ë²•ë ¹ ë‚´ìš©ì—ì„œ ì°¾ê³ ì í•˜ëŠ” ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì¤˜. ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ë©´ì„œë„ ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ë˜ëŠ” ê²€ìƒ‰ ëŒ€ìƒì—ì„œ ì œì™¸í•´ì•¼ í•  ë‹¨ì–´ëŠ” ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¨, ì§ˆë¬¸ ì†ì— ì˜ë¯¸ê°€ ìœ ì‚¬í•œ ë‹¨ì–´ê°€ ë“±ì¥í•˜ëŠ” ê²½ìš°ì—ëŠ” ì–´ëŠ ë‹¨ì–´ë¡œ ê²€ìƒ‰í•´ì•¼ ë§¤ì¹­ì´ ë” ì¢‹ì„ì§€ ëª¨ë¥´ë¯€ë¡œ ëª¨ë‘ í¬í•¨í•´ì£¼ì„¸ìš”. ëª…ì‚¬ ìœ„ì£¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
""",
                },
                {"role": "user", "content": f"ë¬¸ì¥: {query}"},
            ]

            # SimpleToolCaller ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            caller = SimpleToolCaller()

            # ì§ˆë¬¸ì— ë²•ë ¹ ì´ë¦„ì´ í¬í•¨ëœ ê²½ìš° ì¶”ì¶œ
            law_name_result = caller.chat(messages_law_name, with_tools=False)
            print("ğŸ” LAW NAME RESULT-->", law_name_result)
            print("-" * 100)
            law_name_parsed = self.parse_law_results(law_name_result)
            print("+" * 100)
            print("ğŸ” LAW NAME PARSED-->", law_name_parsed)

            # ì§ˆë¬¸ì—ì„œ ì°¾ê³ ì í•˜ëŠ” ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
            keyword = caller.chat(messages_keyword, with_tools=False)
            # ë§¨ ì•ì— í‚¤ì›Œë“œ: ê°€ ìˆìœ¼ë©´ ì œê±°
            if keyword.startswith("í‚¤ì›Œë“œ:"):
                keyword = keyword[len("í‚¤ì›Œë“œ:") :]
            # ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            keyword = keyword.split(",")
            keyword = [keyword.strip() for keyword in keyword]
            # í‚¤ì›Œë“œ ì¤‘ ë²•ë¥ ëª…ì´ í¬í•¨ëœ ê²½ìš° ì œê±°
            keyword = [
                keyword
                for keyword in keyword
                if keyword not in law_name_parsed[0]["ë²•ë¥ ëª…"]
            ]
            print("ğŸ” KEYWORD-->", keyword)

            # execute sql
            # SELECT ch2.id, ch2.text, ch2.meta, document.document_meta, paradedb.score(ch2.id) similarity
            # FROM document JOIN collection cl ON document.collection_id = cl.id join chunk ch2 on ch2.document_id = document.id join embedding_all ea on ea.chunk_id = ch2.id
            # WHERE cl.usage = 'rag' AND (cl.scenario->>'law_no_ordin' = 'Y')  AND (NOT document.collection_id = 4 AND document.document_meta->>'path' NOT ILIKE '/data/law/ordin/%') and keyword1='ê±´ì¶•ë²•' and ((text @@@ 'ê²½ë¯¸ ë³€ê²½'))
            # ORDER BY paradedb.score(ch2.id) desc LIMIT 80;
            sql_query = f"""
            SELECT ch2.id, ch2.text, ch2.meta, document.document_meta, paradedb.score(ch2.id) similarity
            FROM document JOIN collection cl ON document.collection_id = cl.id join chunk ch2 on ch2.document_id = document.id join embedding_all ea on ea.chunk_id = ch2.id
            WHERE cl.usage = 'rag' AND (cl.scenario->>'law_no_ordin' = 'Y')  AND (NOT document.collection_id = 4 AND document.document_meta->>'path' NOT ILIKE '/data/law/ordin/%') and keyword1='{law_name_parsed[0]["ë²•ë¥ ëª…"]}' and ((text @@@ '{" ".join(keyword)}'))
            ORDER BY paradedb.score(ch2.id) desc LIMIT 80;
            """
            print("ğŸ” SQL QUERY-->", sql_query)
            try:
                db = psycopg2.connect(
                    host=os.getenv("POSTGRES_HOST"),
                    port=os.getenv("POSTGRES_PORT"),
                    database=os.getenv("POSTGRES_DB"),
                    user=os.getenv("POSTGRES_USER"),
                    password=os.getenv("POSTGRES_PASS"),
                )
                cursor = db.cursor()
                cursor.execute(sql_query)
                results = cursor.fetchall()
                for result in results:
                    self.search_results_dict[result[0]] = {
                        "id": result[0],
                        "text": result[1],
                        "meta": result[2],
                        "document_meta": result[3],
                    }
                cursor.close()
                db.close()
            except Exception as e:
                print(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
                return {"error": f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {str(e)}"}

        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
        if len(self.search_results_dict) == 0:
            return {"error": f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."}

        # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        # print("ğŸ” SEARCH RESULTS DICT-->", self.search_results_dict)
        self.search_results = list(self.search_results_dict.values())
        # print("ğŸ” SEARCH RESULTS-->", self.search_results)
        print(f"{self.current_index=} {len(self.search_results)=}")

        # í˜„ì¬ ì¸ë±ìŠ¤ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ê²½ìš°
        if self.current_index >= len(self.search_results):
            return {"error": "ë” ì´ìƒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."}

        # í˜„ì¬ ê²°ê³¼ ë°˜í™˜
        result = self.search_results[self.current_index]
        self.current_index += 1

        return result


# ì „ì—­ LawSearcher ì¸ìŠ¤í„´ìŠ¤
law_searcher = LawSearcher()


# ë²•ë ¹ ê²€ìƒ‰ í•¨ìˆ˜ (ê¸°ì¡´ í•¨ìˆ˜ë¥¼ ë˜í¼ë¡œ ë³€ê²½)
def search_laws(query: str) -> Dict[str, Any]:
    """ì§ˆë¬¸ì— ê´€ë ¨ëœ ë²•ë ¹ë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤. í˜¸ì¶œí•  ë•Œë§ˆë‹¤ ë‹¤ìŒ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return law_searcher.search_laws(query)


# ë²•ë ¹ ë‚´ìš© ì¶©ë¶„ì„± ê²€ì‚¬ í•¨ìˆ˜ (LLM ê¸°ë°˜)
def check_law_sufficiency(law_content: str, user_question: str) -> str:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ë²•ë ¹ ë‚´ìš©ì´ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸°ì— ì¶©ë¶„í•œì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
    # LLMì„ ì‚¬ìš©í•˜ì—¬ ì¶©ë¶„ì„± íŒë‹¨
    messages = [
        {
            "role": "system",
            "content": """ë‹¹ì‹ ì€ ë²•ë ¹ ë‚´ìš©ì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸°ì— ì¶©ë¶„í•œì§€ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

íŒë‹¨ ê¸°ì¤€:
1. ë²•ë ¹ ë‚´ìš©ì´ ì§ˆë¬¸ì˜ í•µì‹¬ ìš”êµ¬ì‚¬í•­ì„ ì§ì ‘ì ìœ¼ë¡œ ë‹¤ë£¨ê³  ìˆëŠ”ê°€?
2. êµ¬ì²´ì ì¸ ì¡°í•­, ì •ì˜, ê¸°ì¤€, ì ˆì°¨ ë“±ì´ ëª…ì‹œë˜ì–´ ìˆëŠ”ê°€?
3. ë‚´ìš©ì˜ ê¸¸ì´ì™€ ìƒì„¸ë„ê°€ ì ì ˆí•œê°€?

ë‹µë³€ í˜•ì‹:
- "ì¶©ë¶„í•¨": ë²•ë ¹ ë‚´ìš©ì´ ì§ˆë¬¸ì— ëŒ€í•œ ì™„ì „í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆëŠ” ê²½ìš°
- "ë¶€ë¶„ì  ì¶©ë¶„í•¨": ì¼ë¶€ ë‹µë³€ì€ ê°€ëŠ¥í•˜ì§€ë§Œ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°  
- "ë¶€ì¡±í•¨": ë²•ë ¹ ë‚´ìš©ì´ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸°ì— ë¶€ì¡±í•œ ê²½ìš°

ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ íŒë‹¨ ê²°ê³¼ë§Œ ë‹µë³€í•˜ì„¸ìš”.""",
        },
        {
            "role": "user",
            "content": f"""ì‚¬ìš©ì ì§ˆë¬¸: {user_question}

ë²•ë ¹ ë‚´ìš©:
{law_content}

ìœ„ ë²•ë ¹ ë‚´ìš©ì´ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸°ì— ì¶©ë¶„í•œì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.""",
        },
    ]

    try:
        # ì§ì ‘ LLM í˜¸ì¶œ (tool calling ì—†ì´)
        headers = {
            "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
            "Content-Type": "application/json",
        }

        data = {"model": "gpt-3.5-turbo", "messages": messages, "temperature": 0.7}

        response = requests.post(
            "https://api.openai.com/v1/chat/completions", headers=headers, json=data
        )

        if response.status_code == 200:
            judgment = response.json()["choices"][0]["message"]["content"]
            return f"ì¶©ë¶„ì„± íŒë‹¨ ê²°ê³¼: {judgment}"
        else:
            return f"API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code} - {response.text}"

    except Exception as e:
        return f"ì¶©ë¶„ì„± íŒë‹¨ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


# ê´€ë ¨ ë²•ë ¹ ì°¾ê¸° ë° ê²€í†  í•¨ìˆ˜
def find_relevant_laws(user_question: str, max_search_count: int = 10) -> str:
    """ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë²•ë ¹ì„ ì°¾ê³  í•˜ë‚˜ì”© ê²€í† í•˜ì—¬ ê´€ë ¨ëœ ë²•ë ¹ì„ ì¶”ë ¤ëƒ…ë‹ˆë‹¤."""

    relevant_laws = []
    insufficient_laws = []
    search_count = 0

    try:
        # ë²•ë ¹ ê²€ìƒ‰ ë° ì¶©ë¶„ì„± ê²€ì‚¬ ë°˜ë³µ
        while search_count < max_search_count:
            search_count += 1

            # ë²•ë ¹ ê²€ìƒ‰
            law_result = search_laws(user_question)

            # ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš°
            if "error" in law_result:
                print(f"ğŸ” LAW SEARCH ERROR: {law_result['error']}")
                break

            # print(
            #     "ğŸ” LAW RESULT(from search_laws)-->",
            #     law_result["document_meta"]["path"],
            #     law_result["meta"],
            # )

            # ë²•ë ¹ ë‚´ìš© ì¶”ì¶œ
            law_content = law_result.get("text", "")
            if not law_content:
                continue

            # ì¶©ë¶„ì„± ê²€ì‚¬
            sufficiency_result = check_law_sufficiency(law_content, user_question)

            # ê²°ê³¼ ë¶„ë¥˜
            if "ì¶©ë¶„í•¨" in sufficiency_result:
                relevant_laws.append(
                    {
                        "content": law_content,
                        "result": law_result,
                        "sufficiency": sufficiency_result,
                    }
                )
            elif "ë¶€ë¶„ì  ì¶©ë¶„í•¨" in sufficiency_result:
                relevant_laws.append(
                    {
                        "content": law_content,
                        "result": law_result,
                        "sufficiency": sufficiency_result,
                    }
                )
            else:
                insufficient_laws.append(
                    {
                        "content": law_content,
                        "result": law_result,
                        "sufficiency": sufficiency_result,
                    }
                )

        #         # ê²°ê³¼ ì •ë¦¬
        #         result_summary = f"""
        # === ë²•ë ¹ ê²€ìƒ‰ ë° ê²€í†  ê²°ê³¼ ===
        # ê²€ìƒ‰í•œ ë²•ë ¹ ìˆ˜: {search_count}ê°œ
        # ì¶©ë¶„í•œ ë²•ë ¹ ìˆ˜: {len([law for law in relevant_laws if "ì¶©ë¶„í•¨" in law["sufficiency"]])}ê°œ
        # ë¶€ë¶„ì  ì¶©ë¶„í•œ ë²•ë ¹ ìˆ˜: {len([law for law in relevant_laws if "ë¶€ë¶„ì  ì¶©ë¶„í•¨" in law["sufficiency"]])}ê°œ
        # ë¶€ì¡±í•œ ë²•ë ¹ ìˆ˜: {len(insufficient_laws)}ê°œ

        # === ì¶©ë¶„í•œ ë²•ë ¹ë“¤ ===
        # """

        #         for i, law in enumerate(relevant_laws, 1):
        #             result_summary += f"""
        # ë²•ë ¹ {i}:
        # text: {law["result"]["text"]}
        # meta: {law["result"]["meta"]}
        # path: {law["result"]["document_meta"]["path"]}
        # ì¶©ë¶„ì„±: {law["sufficiency"]}
        # """

        #         if insufficient_laws:
        #             result_summary += "\n=== ë¶€ì¡±í•œ ë²•ë ¹ë“¤ ===\n"
        #             for i, law in enumerate(insufficient_laws, 1):
        #                 result_summary += f"""
        # ë²•ë ¹ {i}:
        # text: {law["result"]["text"]}
        # meta: {law["result"]["meta"]}
        # path: {law["result"]["document_meta"]["path"]}
        # ì¶©ë¶„ì„±: {law["sufficiency"]}
        # """

        if not relevant_laws:
            return "\nâš ï¸ ì¶©ë¶„í•œ ë²•ë ¹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•˜ê±°ë‚˜ ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”."

        result_summary = ""
        for law in relevant_laws:
            result_summary += f"""
            {law["result"]["document_meta"]["path"]}
            {law["sufficiency"]}
            """
        return result_summary

    except Exception as e:
        return f"ë²•ë ¹ ê²€ìƒ‰ ë° ê²€í†  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
